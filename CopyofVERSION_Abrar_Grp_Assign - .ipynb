{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3e1959b",
   "metadata": {},
   "source": [
    "# EDA, DP, FE & Baseline ML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-imports-001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSOLIDATED SETUP CELL: ALL IMPORTS, CONFIGURATIONS & PATH MANAGEMENT\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import unicodedata\n",
    "import textwrap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data Processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scientific Computing\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Scikit-learn: Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "# Scikit-learn: Model Selection\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "\n",
    "# Scikit-learn: Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Scikit-learn: Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Optional: XGBoost\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    has_xgb = True\n",
    "except Exception:\n",
    "    has_xgb = False\n",
    "    print(\"⚠ Warning: XGBoost not installed. Gradient Boosting model will be skipped.\")\n",
    "\n",
    "# Imbalanced-learn: Balancing techniques\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE, SMOTENC, RandomOverSampler\n",
    "    from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "    from imblearn.combine import SMOTETomek\n",
    "    has_imblearn = True\n",
    "except Exception:\n",
    "    has_imblearn = False\n",
    "    print(\"⚠ Warning: imbalanced-learn not installed. Run: pip install imbalanced-learn\")\n",
    "\n",
    "# Text processing\n",
    "try:\n",
    "    from rapidfuzz import process, fuzz\n",
    "except Exception:\n",
    "    print(\"⚠ Warning: rapidfuzz not installed. Run: pip install rapidfuzz\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', 200)\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "\n",
    "# PATH MANAGEMENT: Dataset & Output Folder Setup\n",
    "\n",
    "# Get notebook directory (where this notebook is located)\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "print(f\"Notebook Directory: {NOTEBOOK_DIR}\")\n",
    "\n",
    "# Dataset filename and location\n",
    "DATASET_NAME = 'PPD_dataset_v2'\n",
    "DATASET_FILENAME = f'{DATASET_NAME}.csv'\n",
    "DATASET_PATH = NOTEBOOK_DIR / DATASET_FILENAME\n",
    "\n",
    "# Create output folder (same location as notebook, subfolder named after dataset)\n",
    "OUTPUT_FOLDER = NOTEBOOK_DIR / f'{DATASET_NAME}_outputs'\n",
    "OUTPUT_FOLDER.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Dataset Path: {DATASET_PATH}\")\n",
    "print(f\"Output Folder: {OUTPUT_FOLDER}\")\n",
    "\n",
    "# Verify dataset exists\n",
    "if not DATASET_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Dataset not found: {DATASET_PATH}\\nPlease ensure '{DATASET_FILENAME}' is in the notebook directory.\")\n",
    "else:\n",
    "    print(f\"✓ Dataset found: {DATASET_FILENAME}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"✓ Output files will be saved to: {OUTPUT_FOLDER}\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d709ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset safely with proper encoding\n",
    "csv_path = str(DATASET_PATH)   # adjust path if needed\n",
    "\n",
    "# Try UTF-8 first, fallback to Latin-1 if UnicodeDecodeError occurs\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(csv_path, encoding='latin1')\n",
    "\n",
    "print(\"File loaded successfully!\")\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491b478e",
   "metadata": {},
   "source": [
    "## Column type detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a241955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-detect numeric and categorical columns\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "# Print column types\n",
    "print(f\"Numeric columns ({len(num_cols)}): {num_cols}\")\n",
    "print(f\"Categorical columns ({len(cat_cols)}): {cat_cols}\")\n",
    "\n",
    "# Missing values summary with counts and percentages\n",
    "missing = df.isnull().sum().sort_values(ascending=False)\n",
    "missing = missing[missing > 0]\n",
    "\n",
    "if not missing.empty:\n",
    "    missing_df = pd.DataFrame({\n",
    "        'Features': missing.index,\n",
    "        'Missing Count': missing.values,\n",
    "        'Missing %': round((missing / len(df)) * 100, 2).values\n",
    "    })\n",
    "    missing_df = missing_df.reset_index(drop=True)\n",
    "    print(\"\\nColumns with missing values:\")\n",
    "    display(missing_df)\n",
    "else:\n",
    "    print(\"\\nNo missing values found in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e158f5e6",
   "metadata": {},
   "source": [
    "## Plotting plan\n",
    "- For **numerical: histograms**\n",
    "- For **categorical: bar charts**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea52829e",
   "metadata": {},
   "source": [
    "## Individual Histogram for the numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d1a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude 'sr' or similar non-informative numeric columns\n",
    "num_cols_clean = [c for c in num_cols if c.lower() not in ['sr', 's.no', 'serial', 'id']]\n",
    "\n",
    "# Plot histograms for numeric columns\n",
    "n = len(num_cols_clean)\n",
    "if n == 0:\n",
    "    print(\"No numeric columns detected (after removing ID fields).\")\n",
    "else:\n",
    "    ncols = 3\n",
    "    nrows = (n + ncols - 1) // ncols\n",
    "    plt.figure(figsize=(5 * ncols, 4 * nrows))\n",
    "    for i, c in enumerate(num_cols_clean, 1):\n",
    "        plt.subplot(nrows, ncols, i)\n",
    "        sns.histplot(df[c].dropna(), kde=True, bins=30)\n",
    "        plt.title(f\"{c}\\n(skew={df[c].dropna().skew():.2f})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7230b2fd",
   "metadata": {},
   "source": [
    "## Top 5 numeric plots (choosing & statistically explanating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eda3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'target' with the actual target column name if known, e.g. 'PHQ9 Result' or 'EPDS Result'\n",
    "target_col = 'EPDS Result' if 'EPDS Result' in df.columns else None  \n",
    "\n",
    "# Identify ID-like non-informative numeric columns (plot them separately)\n",
    "id_like = [c for c in num_cols if c.lower() in ['sr', 's.no', 'serial', 'id']]\n",
    "num_cols_clean = [c for c in num_cols if c not in id_like]\n",
    "\n",
    "# Select top 5 most important numeric features (by variance) from the informative set\n",
    "if len(num_cols_clean) > 5:\n",
    "    variances = df[num_cols_clean].var().sort_values(ascending=False)\n",
    "    top5 = variances.head(5).index.tolist()\n",
    "else:\n",
    "    top5 = num_cols_clean\n",
    "\n",
    "print(\"Top 5 numeric features (by variance):\", top5)\n",
    "\n",
    "# Plot each of the top-5 in its own figure for clearer inspection\n",
    "for c in top5:\n",
    "    data_c = df[c].dropna()\n",
    "    skew_c = data_c.skew() if not data_c.empty else float('nan')\n",
    "    var_c = data_c.var() if not data_c.empty else float('nan')\n",
    "    mean_c = data_c.mean() if not data_c.empty else float('nan')\n",
    "    median_c = data_c.median() if not data_c.empty else float('nan')\n",
    "    min_c = data_c.min() if not data_c.empty else float('nan')\n",
    "    max_c = data_c.max() if not data_c.empty else float('nan')\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.histplot(data_c, kde=True, bins=30)\n",
    "    plt.title(f\"{c}\\n(skew={skew_c:.2f}, var={var_c:.2f})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # quick textual explanation template\n",
    "    print(f\"Summary for {c}: mean={mean_c:.2f}, median={median_c:.2f}, min={min_c:.2f}, max={max_c:.2f}, skew={skew_c:.2f}, var={var_c:.2f}\\n\")\n",
    "\n",
    "# Display ID-like / non-informative numeric columns separately with a clear title\n",
    "if len(id_like) > 0:\n",
    "    if len(id_like) == 1:\n",
    "        c = id_like[0]\n",
    "        plt.figure(figsize=(8,3))\n",
    "        sns.histplot(df[c].dropna(), kde=False, bins=30)\n",
    "        plt.title(\"non-informative numeric columns: \" + c)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.figure(figsize=(6 * len(id_like), 4))\n",
    "        for i, c in enumerate(id_like, 1):\n",
    "            plt.subplot(1, len(id_like), i)\n",
    "            sns.histplot(df[c].dropna(), kde=False, bins=30)\n",
    "            plt.title(c)\n",
    "        plt.suptitle(\"non-informative numeric columns\")\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcc712b",
   "metadata": {},
   "source": [
    "## Text Normalization & Fuzzy Deduplication (Preserve NaN/None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419cd449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smart Text Normalization & Fuzzy Deduplication (Preserve NaN/None)\n",
    "\n",
    "\n",
    "df.columns = df.columns.str.encode('ascii', 'ignore').str.decode('ascii')\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "\n",
    "# --- STEP 1: Fix encoding issues ---\n",
    "def normalize_text(s):\n",
    "    if isinstance(s, str):\n",
    "        s = unicodedata.normalize('NFKD', s)\n",
    "        s = s.replace('’', \"'\").replace('‘', \"'\").replace('“', '\"').replace('”', '\"')\n",
    "        return s.strip()\n",
    "    return s\n",
    "\n",
    "df = df.map(normalize_text)\n",
    "\n",
    "# --- STEP 2: Identify categorical columns ---\n",
    "cat_cols = df.select_dtypes(exclude=['number', 'bool']).columns.tolist()\n",
    "\n",
    "# --- STEP 3: Clean casing, spaces, punctuation ---\n",
    "def clean_string(s):\n",
    "    if isinstance(s, str):\n",
    "        s = s.lower().strip()\n",
    "        s = s.replace('-', ' ').replace('_', ' ')\n",
    "        s = ' '.join(s.split())  # remove extra spaces\n",
    "        return s\n",
    "    return s\n",
    "\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].map(clean_string)\n",
    "\n",
    "# --- STEP 4: Fuzzy deduplication preserving NaNs as a counted category ---\n",
    "def fuzzy_standardize_column(series, threshold=85, sentinel='NaN', keep_missing_label=True):\n",
    "    \"\"\"\n",
    "    - Treat missing values as a category by filling with `sentinel` before matching.\n",
    "    - If keep_missing_label=True the output will contain the sentinel string (so missing counts as a category).\n",
    "      If False, sentinel is converted back to np.nan at the end (preserve NaN).\n",
    "    \"\"\"\n",
    "    # Work on a filled series so missing is included in unique values\n",
    "    filled = series.fillna(sentinel).astype(object)\n",
    "    # Process values in descending frequency so the most common form becomes canonical\n",
    "    unique_vals = pd.Series(filled.value_counts().index.tolist())\n",
    "    mapping = {}\n",
    "\n",
    "    for val in unique_vals:\n",
    "        # first mapped value becomes canonical\n",
    "        if not mapping:\n",
    "            mapping[val] = val\n",
    "            continue\n",
    "        # fuzzy match against existing canonical keys\n",
    "        match, score, _ = process.extractOne(val, list(mapping.keys()), scorer=fuzz.ratio)\n",
    "        if score >= threshold:\n",
    "            mapping[val] = match\n",
    "        else:\n",
    "            mapping[val] = val\n",
    "\n",
    "    # apply mapping to filled series\n",
    "    mapped = filled.map(mapping)\n",
    "\n",
    "    # optionally convert sentinel back to np.nan to preserve original NaN semantics\n",
    "    if not keep_missing_label:\n",
    "        mapped = mapped.replace({sentinel: np.nan})\n",
    "\n",
    "    return mapped, mapping\n",
    "\n",
    "# --- STEP 5: Apply fuzzy matching (keep_missing_label=True to count missing as a unique category) ---\n",
    "for col in cat_cols:\n",
    "    print(f\"\\nCleaning column: {col}\")\n",
    "    # count uniques including missing by using fillna(sentinel)\n",
    "    before_unique = df[col].fillna('NaN').unique()\n",
    "    before_count = len([x for x in before_unique if x is not None])\n",
    "    df[col], mapping = fuzzy_standardize_column(df[col], threshold=85, sentinel='NaN', keep_missing_label=True)\n",
    "    after_unique = df[col].fillna('NaN').unique()\n",
    "    n_before = len([x for x in before_unique if pd.notna(x)])\n",
    "    n_after = len([x for x in after_unique if pd.notna(x)])\n",
    "    print(f\"  Unique before (counting missing): {n_before} → after: {n_after}\")\n",
    "    print(\"  Example mappings (changed values):\")\n",
    "    shown = 0\n",
    "    for k, v in mapping.items():\n",
    "        if k != v:\n",
    "            print(f\"    '{k}' → '{v}'\")\n",
    "            shown += 1\n",
    "            if shown >= 6:\n",
    "                break\n",
    "\n",
    "# --- STEP 6: Check for non-ASCII characters ---\n",
    "for col in cat_cols:\n",
    "    bad_chars = df[col].astype(str).str.contains(r'[^\\x00-\\x7F]', regex=True)\n",
    "    if bad_chars.any():\n",
    "        print(f\"Warning: Non-ASCII characters remain in column '{col}'\")\n",
    "\n",
    "print(\"\\nNormalization & fuzzy deduplication complete (missing values can be counted as a category).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80df4c81",
   "metadata": {},
   "source": [
    "## Individual Bar Chart for the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3abb480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For categorical features: value counts\n",
    "if len(cat_cols) == 0:\n",
    "    print(\"No categorical columns detected.\")\n",
    "else:\n",
    "    for c in cat_cols:\n",
    "        vc = df[c].value_counts(dropna=False)\n",
    "        # limit plotting for very high-cardinality columns\n",
    "        plt.figure(figsize=(8,3))\n",
    "        if len(vc) <= 30:\n",
    "            sns.barplot(x=vc.index.astype(str), y=vc.values)\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "        else:\n",
    "            # show top 20 categories\n",
    "            sns.barplot(x=vc.head(20).index.astype(str), y=vc.head(20).values)\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "        plt.title(f\"Value counts for {c} (unique={df[c].nunique()})\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9230ba4a",
   "metadata": {},
   "source": [
    "## Top 5 categorical plots (choosing & explaining including statistics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2548d911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Top 5 conceptually relevant categorical plots for PPD detection ---\n",
    "top5_cat = [\n",
    "    'Feeling about motherhood',\n",
    "    'Relationship with husband',\n",
    "    'Relationship with husband',\n",
    "    'Recieved Support',\n",
    "    'Depression during pregnancy (PHQ2)'\n",
    "]\n",
    "# Explanations dictionary\n",
    "explanations = {\n",
    "    'Depression during pregnancy (PHQ2)': \"Pre-existing or concurrent depression is the strongest predictor of PPD.\",\n",
    "    'Recieved Support': \"Social support (from husband, family, friends) buffers against PPD.\",\n",
    "    'Relationship with husband': \"Marital relationship quality is crucial in Bangladeshi households where extended family often influences daily life.\",\n",
    "    'History of pregnancy loss': \"Prior loss is stressful and can increase anxiety and PPD risk.\",\n",
    "    'Feeling about motherhood': \"Maternal feelings toward the newborn and self-efficacy are direct psychological indicators of vulnerability.\"\n",
    "}\n",
    "\n",
    "print(\"Top-5 categorical columns selected for PPD analysis:\", top5_cat)\n",
    "\n",
    "for c in top5_cat:\n",
    "    vc = df[c].value_counts(dropna=False)\n",
    "    vc_norm = df[c].value_counts(normalize=True).round(3)\n",
    "    \n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.barplot(x=vc.index.astype(str), y=vc.values)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"{c} (unique={df[c].nunique()})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "        # Print explanation\n",
    "    print(\"\\nExplanation:\")\n",
    "    print(explanations[c])\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "    \n",
    "    print(f\"Value counts for '{c}':\")\n",
    "    print(vc)\n",
    "    print(\"\\nNormalized (proportion) counts:\")\n",
    "    print(vc_norm)\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccec5296",
   "metadata": {},
   "source": [
    "## Categorical vs Categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6b4a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Categorical vs Categorical analysis for PPD (single figure, blue/orange) ---\n",
    "target_col = 'EPDS Result'\n",
    "\n",
    "# Increase figure size for readability\n",
    "fig, axes = plt.subplots(3, 2, figsize=(24, 20))  # bigger width & height\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, c in enumerate(top5_cat):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Countplot\n",
    "    sns.countplot(data=df, x=c, hue=target_col, ax=ax)\n",
    "    \n",
    "    # Rotate x-axis labels safely\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right', fontsize=12)\n",
    "    \n",
    "    # Improve y-axis and title font sizes\n",
    "    ax.set_ylabel(\"Count\", fontsize=14)\n",
    "    ax.set_title(f\"{c} vs {target_col}\", fontsize=16)\n",
    "    \n",
    "    # Legend fonts\n",
    "    ax.legend(title=target_col, fontsize=12, title_fontsize=14)\n",
    "    \n",
    "    # --- Text outputs below each subplot ---\n",
    "    print(f\"Analyzing '{c}' vs {target_col}\")\n",
    "    \n",
    "    # Cross-tabulation\n",
    "    ct = pd.crosstab(df[c], df[target_col])\n",
    "    print(\"\\nCross-tabulation:\")\n",
    "    display(ct)\n",
    "    \n",
    "    # Normalized proportions\n",
    "    ct_norm = pd.crosstab(df[c], df[target_col], normalize='index').round(3)\n",
    "    print(\"\\nNormalized proportions (row-wise):\")\n",
    "    display(ct_norm)\n",
    "    \n",
    "    # Explanation printed below tables\n",
    "    print(f\"Explanation for '{c}': {explanations[c]}\")\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "\n",
    "# Remove empty subplot if exists\n",
    "if len(top5_cat) < len(axes):\n",
    "    for j in range(len(top5_cat), len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc47e89e",
   "metadata": {},
   "source": [
    "## Categorical vs Numerical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13fa392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Categorical vs Numerical analysis for PPD (big square layout, no duplicates) ---\n",
    "numeric_cols = ['Age', 'Number of the latest pregnancy', 'PHQ9 Score', 'EPDS Score']\n",
    "\n",
    "for num_col in numeric_cols:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(24, 16))  # 2 rows x 3 columns\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    print(f\"Analyzing '{num_col}' vs \")\n",
    "    for i, cat_col in enumerate(top5_cat):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Boxplot: numeric vs categorical\n",
    "        sns.boxplot(data=df, x=cat_col, y=num_col, hue='EPDS Result', ax=ax, palette='pastel')\n",
    "        \n",
    "        # Titles and labels\n",
    "        ax.set_title(f\"{num_col} vs {cat_col}\", fontsize=14)\n",
    "        ax.set_xlabel(cat_col, fontsize=12)\n",
    "        ax.set_ylabel(num_col, fontsize=12)\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha='right', fontsize=11)\n",
    "        ax.tick_params(axis='y', labelsize=11)\n",
    "        \n",
    "        # Legend only for first subplot\n",
    "        if i != 0:\n",
    "            ax.get_legend().remove()\n",
    "        else:\n",
    "            ax.legend(title='EPDS Result', fontsize=11, title_fontsize=12)\n",
    "        \n",
    "        # --- Summary statistics (one print per numeric x categorical pair) ---\n",
    "        display(df.groupby(cat_col)[num_col].describe())\n",
    "        print(\"\\n\" + \"-\"*100 + \"\\n\")\n",
    "    \n",
    "    # Remove any empty subplot (6th subplot in 2x3 grid)\n",
    "    if len(top5_cat) < len(axes):\n",
    "        for j in range(len(top5_cat), len(axes)):\n",
    "            fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61872df7",
   "metadata": {},
   "source": [
    "## Numerical vs Numerical pair plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ed31fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Numerical vs Numerical analysis for PPD (darker pastel) ---\n",
    "numeric_cols = ['Age', 'Number of the latest pregnancy', 'PHQ9 Score', 'EPDS Score']\n",
    "target_col = 'EPDS Result'\n",
    "\n",
    "# Create slightly darker pastel palette\n",
    "n_classes = df[target_col].nunique()\n",
    "base_palette = sns.color_palette(\"pastel\", n_colors=n_classes)\n",
    "darker_palette = [(r*0.8, g*0.8, b*0.8) for r, g, b in base_palette]\n",
    "\n",
    "# Pairplot with hue = EPDS Result\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.pairplot(df[numeric_cols + [target_col]], \n",
    "             hue=target_col, \n",
    "             palette=darker_palette,  # darker pastel\n",
    "             diag_kind='kde', \n",
    "             corner=False)  # corner=False shows full matrix\n",
    "\n",
    "plt.suptitle(\"Numerical vs Numerical Pair Plot for PPD\", fontsize=18, y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa878d50",
   "metadata": {},
   "source": [
    "## Missing data handling strategy\n",
    "1. Show missing % per column.  \n",
    "2. Impute numeric columns with median (configurable).  \n",
    "3. Impute categorical with mode or 'missing' label.  \n",
    "4. Optionally use KNNImputer for more advanced imputation (not included by default).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9cad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Strip leading/trailing spaces from column names ---\n",
    "df.columns = df.columns.str.strip()\n",
    "cat_cols = [c.strip() for c in cat_cols]\n",
    "num_cols = [c.strip() for c in num_cols if c.strip() != 'sr']  # remove 'sr'\n",
    "\n",
    "# --- Missing values BEFORE imputation (using same approach as before) ---\n",
    "missing_before = df.isnull().sum().sort_values(ascending=False)\n",
    "missing_before = missing_before[missing_before > 0]\n",
    "\n",
    "missing_before_df = pd.DataFrame({\n",
    "    'Features': missing_before.index,\n",
    "    'Missing Count (Before)': missing_before.values,\n",
    "    'Missing % (Before)': round((missing_before / len(df)) * 100, 2).values\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# --- Copy dataframe for preprocessing ---\n",
    "df_proc = df.copy()\n",
    "\n",
    "# --- Numeric imputation ---\n",
    "use_knn = False  # Set True to use KNN imputer, False to use median\n",
    "\n",
    "if len(num_cols) > 0:\n",
    "    if use_knn:\n",
    "        knn_imputer = KNNImputer(n_neighbors=5)\n",
    "        df_proc[num_cols] = knn_imputer.fit_transform(df_proc[num_cols])\n",
    "    else:\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        df_proc[num_cols] = num_imputer.fit_transform(df_proc[num_cols])\n",
    "\n",
    "# --- Categorical imputation ---\n",
    "for c in cat_cols:\n",
    "    df_proc[c] = df_proc[c].fillna('Missing')\n",
    "\n",
    "# --- Missing values AFTER imputation (same columns as before) ---\n",
    "missing_after = df_proc[missing_before.index].isnull().sum()\n",
    "missing_after_df = pd.DataFrame({\n",
    "    'Features': missing_after.index,\n",
    "    'Missing Count (After)': missing_after.values,\n",
    "    'Missing % (After)': round((missing_after / len(df_proc)) * 100, 2).values\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# --- Combined table: Before vs After ---\n",
    "missing_summary = pd.concat([\n",
    "    missing_before_df[['Features']],\n",
    "    missing_after_df[['Missing Count (After)', 'Missing % (After)']]\n",
    "], axis=1)\n",
    "\n",
    "print(\"Missing Data Handling: After Imputation\")\n",
    "display(missing_summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d188ade4",
   "metadata": {},
   "source": [
    "## Stratified sampling\n",
    "We will split data into train/test preserving the target distribution using `stratify=y`.  \n",
    "**Important:** set `target_col` to the actual target variable name in your dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046e8028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Target column ---\n",
    "target_col = 'EPDS Result'   # replace if needed\n",
    "\n",
    "if target_col not in df_proc.columns:\n",
    "    raise ValueError(f\"Target column '{target_col}' not found. Update target_col variable.\")\n",
    "\n",
    "# Features & target\n",
    "X = df_proc.drop(columns=[target_col])\n",
    "y = df_proc[target_col]\n",
    "\n",
    "# Original class distribution\n",
    "print(\"Original class distribution:\")\n",
    "display(Counter(y))\n",
    "\n",
    "# --- Stratified train/test split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,       # 20% test\n",
    "    random_state=42,\n",
    "    stratify=y           # preserves class distribution\n",
    ")\n",
    "\n",
    "# Verify class distribution\n",
    "print(\"\\nTrain class distribution:\")\n",
    "display(Counter(y_train))\n",
    "print(\"\\nTest class distribution:\")\n",
    "display(Counter(y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00fcc24",
   "metadata": {},
   "source": [
    "## One-Hot Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59130da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Identify categorical columns to encode ---\n",
    "cat_cols_to_encode = [c for c in X_train.columns if c in cat_cols]\n",
    "\n",
    "print(f\"Categorical columns to encode ({len(cat_cols_to_encode)}): {cat_cols_to_encode}\")\n",
    "\n",
    "# --- One-hot encoder (handle unknown categories in test set) ---\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit on training data\n",
    "X_train_encoded = ohe.fit_transform(X_train[cat_cols_to_encode])\n",
    "X_test_encoded = ohe.transform(X_test[cat_cols_to_encode])\n",
    "\n",
    "# Column names after encoding\n",
    "encoded_cols = ohe.get_feature_names_out(cat_cols_to_encode)\n",
    "\n",
    "# Convert to DataFrame\n",
    "X_train_ohe = pd.DataFrame(X_train_encoded, columns=encoded_cols, index=X_train.index)\n",
    "X_test_ohe = pd.DataFrame(X_test_encoded, columns=encoded_cols, index=X_test.index)\n",
    "\n",
    "# --- Drop original categorical columns and append encoded ones ---\n",
    "X_train_final = pd.concat([X_train.drop(columns=cat_cols_to_encode), X_train_ohe], axis=1)\n",
    "X_test_final  = pd.concat([X_test.drop(columns=cat_cols_to_encode), X_test_ohe], axis=1)\n",
    "\n",
    "print(\"Training set shape after one-hot encoding:\", X_train_final.shape)\n",
    "print(\"Test set shape after one-hot encoding:\", X_test_final.shape)\n",
    "\n",
    "print(\"\\n--- Sample of One-Hot Encoded Features (first 5 rows) ---\")\n",
    "print(f\"Number of one-hot encoded columns: {len(encoded_cols)}\")\n",
    "display(X_train_ohe.head())\n",
    "\n",
    "print(\"\\n--- One-Hot Encoded Feature Names ---\")\n",
    "print(f\"Total encoded features: {len(encoded_cols)}\")\n",
    "print(\"All encoded column names:\")\n",
    "import textwrap\n",
    "col_list_str = ', '.join(encoded_cols)\n",
    "wrapped_cols = textwrap.fill(col_list_str, width=120)\n",
    "print(wrapped_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42bff33",
   "metadata": {},
   "source": [
    "##  Standardization\n",
    "We will StandardScale numeric features: ['Age', 'Number of the latest pregnancy', 'PHQ9 Score', 'EPDS Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bde1f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric columns to scale\n",
    "num_cols_to_scale = ['Age', 'Number of the latest pregnancy', 'PHQ9 Score', 'EPDS Score']\n",
    "\n",
    "# --- Separate numeric data ---\n",
    "X_train_num = X_train[num_cols_to_scale].copy()\n",
    "X_test_num  = X_test[num_cols_to_scale].copy()\n",
    "\n",
    "# --- Standardization ---\n",
    "scaler = StandardScaler()\n",
    "X_train_num = pd.DataFrame(scaler.fit_transform(X_train_num), \n",
    "                           columns=num_cols_to_scale, index=X_train.index)\n",
    "X_test_num  = pd.DataFrame(scaler.transform(X_test_num), \n",
    "                           columns=num_cols_to_scale, index=X_test.index)\n",
    "\n",
    "# --- Separate categorical (one-hot) columns ---\n",
    "X_train_cat = X_train_ohe.drop(columns=num_cols_to_scale, errors='ignore')\n",
    "X_test_cat  = X_test_ohe.drop(columns=num_cols_to_scale, errors='ignore')\n",
    "\n",
    "# --- Combine numeric + categorical ---\n",
    "X_train_final = pd.concat([X_train_num, X_train_cat], axis=1)\n",
    "X_test_final  = pd.concat([X_test_num, X_test_cat], axis=1)\n",
    "\n",
    "# --- Display after standardization ---\n",
    "print(\"Training set (first 5 rows) - Standardized Numeric Features:\")\n",
    "display(X_train_num.head())\n",
    "\n",
    "print(\"\\nTest set (first 5 rows) - Standardized Numeric Features:\")\n",
    "display(X_test_num.head())\n",
    "\n",
    "print(\"\\nFinal training set shape:\", X_train_final.shape)\n",
    "print(\"Final test set shape:\", X_test_final.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0aeb0f",
   "metadata": {},
   "source": [
    "## Balancing techniques\n",
    "- SMOTE-NC (synthetic oversampling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f4d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not has_imblearn:\n",
    "    print(\"imbalanced-learn not installed. Install with `pip install imbalanced-learn` to use SMOTE-NC.\")\n",
    "else:\n",
    "    # Combine numeric and one-hot encoded categorical features for SMOTE-NC\n",
    "    # X_train has both numeric columns and one-hot encoded categorical columns\n",
    "    X_tr_combined = X_train_final.values  # Combined numeric + one-hot encoded categorical\n",
    "    y_tr = y_train.copy()\n",
    "    \n",
    "    # Encode target if it's categorical\n",
    "    if y_tr.dtype == 'O' or y_tr.dtype.name == 'category':\n",
    "        le = LabelEncoder()\n",
    "        y_tr_enc = le.fit_transform(y_tr)\n",
    "        classes = le.classes_\n",
    "    else:\n",
    "        y_tr_enc = y_tr.values\n",
    "        classes = np.unique(y_tr_enc)\n",
    "    \n",
    "    print(\"Original training distribution:\", Counter(y_tr))\n",
    "    \n",
    "    # Identify categorical feature indices (one-hot encoded columns)\n",
    "    # One-hot encoded features are binary (0 or 1), all others are numeric\n",
    "    categorical_indices = [i for i, col in enumerate(X_train_final.columns) if col not in ['Age', 'Number of the latest pregnancy', 'PHQ9 Score', 'EPDS Score']]\n",
    "    \n",
    "    print(f\"\\nNumeric features: {['Age', 'Number of the latest pregnancy', 'PHQ9 Score', 'EPDS Score']}\")\n",
    "    print(f\"One-hot encoded categorical features: {len(categorical_indices)} columns\")\n",
    "    \n",
    "    # Apply SMOTE-NC (Synthetic Minority Over-sampling Technique for Nominal and Continuous)\n",
    "    sm = SMOTENC(categorical_features=categorical_indices, random_state=42)\n",
    "    X_train_bal, y_train_bal_enc = sm.fit_resample(X_tr_combined, y_tr_enc)\n",
    "    \n",
    "    # Decode back if target was categorical\n",
    "    if y_tr.dtype == 'O' or y_tr.dtype.name == 'category':\n",
    "        y_train_bal = le.inverse_transform(y_train_bal_enc)\n",
    "    else:\n",
    "        y_train_bal = y_train_bal_enc\n",
    "    \n",
    "    print(\"\\nAfter SMOTE-NC (balanced training set):\", Counter(y_train_bal))\n",
    "    print(\"X_train_bal shape:\", X_train_bal.shape)\n",
    "    print(\"y_train_bal shape:\", y_train_bal.shape)\n",
    "    \n",
    "    # Convert balanced data back to DataFrame for display\n",
    "    X_train_bal_df = pd.DataFrame(X_train_bal, columns=X_train_final.columns)\n",
    "    print(\"\\n--- Sample of Features After SMOTE-NC Balancing (first 5 rows) ---\")\n",
    "    display(X_train_bal_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b8e867",
   "metadata": {},
   "source": [
    "## Correlation matrix & feature drop\n",
    "- Approximate mutual information between features and target (for numeric & categorical).\n",
    "- Then drop highly collinear features (threshold configurable).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5eb695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature Correlation Analysis & Feature Drop Suggestions ---\n",
    "\n",
    "# --- Define numeric and categorical columns (exclude serial/ID columns) ---\n",
    "numeric_cols = ['Age', 'Number of the latest pregnancy', 'PHQ9 Score', 'EPDS Score']\n",
    "target_col = 'EPDS Result'\n",
    "\n",
    "# Exclude serial/ID-like non-informative columns\n",
    "id_like_cols = [c for c in df_proc.columns if c.lower() in ['sr', 's.no', 'serial', 'id']]\n",
    "print(f\"Excluding ID-like columns: {id_like_cols}\")\n",
    "\n",
    "# --- Numeric correlation with target ---\n",
    "corr_num = df_proc[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(corr_num, annot=True, fmt=\".2f\", cmap='Blues', cbar=True)\n",
    "plt.title(\"Correlation Matrix (Numeric Features)\")\n",
    "plt.show()\n",
    "\n",
    "# Identify highly correlated numeric features (threshold > 0.85)\n",
    "high_corr_pairs = []\n",
    "threshold = 0.85\n",
    "for i in range(len(numeric_cols)):\n",
    "    for j in range(i+1, len(numeric_cols)):\n",
    "        if abs(corr_num.iloc[i,j]) > threshold:\n",
    "            high_corr_pairs.append((numeric_cols[i], numeric_cols[j], corr_num.iloc[i,j]))\n",
    "\n",
    "if high_corr_pairs:\n",
    "    print(\"Highly correlated numeric feature pairs (consider dropping one):\")\n",
    "    for pair in high_corr_pairs:\n",
    "        print(f\"{pair[0]} <--> {pair[1]} | corr = {pair[2]:.2f}\")\n",
    "else:\n",
    "    print(\"No highly correlated numeric feature pairs found.\")\n",
    "\n",
    "# --- Categorical correlation using Cramér's V ---\n",
    "cat_cols = [c for c in df_proc.columns if c not in numeric_cols + [target_col] + id_like_cols]\n",
    "\n",
    "def cramers_v(x, y):\n",
    "    \"\"\"Robust Cramér's V with bias correction.\n",
    "    Returns 0.0 for degenerate tables and guards against divide-by-zero.\n",
    "    \"\"\"\n",
    "    cm = pd.crosstab(x, y)\n",
    "    n = cm.values.sum()\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "    r, k = cm.shape\n",
    "    if r == 1 or k == 1:\n",
    "        return 0.0\n",
    "    chi2 = chi2_contingency(cm, correction=False)[0]\n",
    "    phi2 = chi2 / n\n",
    "    phi2corr = max(0.0, phi2 - ((k - 1) * (r - 1)) / (n - 1)) if n > 1 else 0.0\n",
    "    rcorr = r - ((r - 1) ** 2) / (n - 1) if n > 1 else r\n",
    "    kcorr = k - ((k - 1) ** 2) / (n - 1) if n > 1 else k\n",
    "    denom = min((kcorr - 1), (rcorr - 1))\n",
    "    if denom <= 0:\n",
    "        return 0.0\n",
    "    return float(np.sqrt(phi2corr / denom))\n",
    "\n",
    "# Compute Cramér's V among categorical features (only top 20 to save time)\n",
    "top_cat = cat_cols[:20]\n",
    "cramers_matrix = pd.DataFrame(index=top_cat, columns=top_cat)\n",
    "\n",
    "for col1 in top_cat:\n",
    "    for col2 in top_cat:\n",
    "        if col1 == col2:\n",
    "            cramers_matrix.loc[col1,col2] = 1.0\n",
    "        else:\n",
    "            cramers_matrix.loc[col1,col2] = cramers_v(df_proc[col1], df_proc[col2])\n",
    "\n",
    "cramers_matrix = cramers_matrix.astype(float)\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(cramers_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True)\n",
    "plt.title(\"Cramér's V Matrix (Categorical Features - Top 20)\")\n",
    "plt.show()\n",
    "\n",
    "# --- Categorical correlation with target ---\n",
    "cramers_target = {}\n",
    "for c in cat_cols:\n",
    "    cramers_target[c] = cramers_v(df_proc[c], df_proc[target_col])\n",
    "cramers_target = pd.Series(cramers_target).sort_values(ascending=False)\n",
    "print(\"Cramér's V with target (top correlated categorical features):\")\n",
    "display(cramers_target.head(15))\n",
    "\n",
    "# --- COMBINED CORRELATION MATRIX: Numeric features vs Target ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMBINED CORRELATION MATRIX: Numeric Features with Target\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Compute correlation of numeric features with target (encoded)\n",
    "le_temp = LabelEncoder()\n",
    "target_encoded = le_temp.fit_transform(df_proc[target_col])\n",
    "\n",
    "numeric_target_corr = {}\n",
    "for col in numeric_cols:\n",
    "    numeric_target_corr[col] = np.corrcoef(df_proc[col].values, target_encoded)[0, 1]\n",
    "\n",
    "numeric_target_df = pd.DataFrame({\n",
    "    'Feature': list(numeric_target_corr.keys()),\n",
    "    'Correlation with Target': list(numeric_target_corr.values())\n",
    "}).sort_values(by='Correlation with Target', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nNumeric Features - Correlation with Target:\")\n",
    "display(numeric_target_df)\n",
    "\n",
    "# Combined visualization: Numeric correlations + categorical associations with target\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 10))\n",
    "\n",
    "# Left: Numeric features correlation with target\n",
    "numeric_target_sorted = pd.Series(numeric_target_corr).sort_values()\n",
    "axes[0].barh(numeric_target_sorted.index, numeric_target_sorted.values, color='steelblue')\n",
    "axes[0].set_xlabel('Correlation Coefficient', fontsize=11)\n",
    "axes[0].set_title('Numeric Features - Correlation with Target', fontsize=12, fontweight='bold')\n",
    "axes[0].axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Right: Top 15 categorical features association with target\n",
    "top_cat_target = cramers_target.head(15)\n",
    "axes[1].barh(range(len(top_cat_target)), top_cat_target.values, color='coral')\n",
    "axes[1].set_yticks(range(len(top_cat_target)))\n",
    "axes[1].set_yticklabels(top_cat_target.index, fontsize=11)\n",
    "axes[1].set_xlabel(\"Cramér's V\", fontsize=11)\n",
    "axes[1].set_title(\"Top 15 Categorical Features - Association with Target\", fontsize=12, fontweight='bold')\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY: Features Most Important for Predicting Target\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Top numeric feature: {numeric_target_df.iloc[0]['Feature']} (corr = {numeric_target_df.iloc[0]['Correlation with Target']:.4f})\")\n",
    "print(f\"Top categorical feature: {cramers_target.index[0]} (Cramér's V = {cramers_target.iloc[0]:.4f})\")\n",
    "\n",
    "# --- Feature drop suggestions ---\n",
    "drop_numeric = [pair[1] for pair in high_corr_pairs] if high_corr_pairs else []\n",
    "drop_categorical = list(cramers_target[cramers_target < 0.05].index)  # weakly correlated\n",
    "\n",
    "print(\"\\nSuggested numeric features to drop (highly correlated):\", drop_numeric)\n",
    "print(\"Suggested categorical features to drop (low association with target):\", drop_categorical)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2817321",
   "metadata": {},
   "source": [
    "##  Outlier removal and Feature Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1da64dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Final Cleaned Feature List & Outlier Removal ---\n",
    "\n",
    "# --- Numeric and categorical columns ---\n",
    "numeric_cols = ['Age', 'Number of the latest pregnancy', 'PHQ9 Score', 'EPDS Score']\n",
    "target_col = 'EPDS Result'\n",
    "cat_cols = [c for c in df_proc.columns if c not in numeric_cols + [target_col]]\n",
    "\n",
    "# --- Step 1: Drop highly correlated numeric features ---\n",
    "corr_num = df_proc[numeric_cols].corr()\n",
    "threshold = 0.9\n",
    "drop_numeric = []\n",
    "\n",
    "for i in range(len(numeric_cols)):\n",
    "    for j in range(i+1, len(numeric_cols)):\n",
    "        if abs(corr_num.iloc[i,j]) > threshold:\n",
    "            drop_numeric.append(numeric_cols[j])\n",
    "\n",
    "final_numeric = [c for c in numeric_cols if c not in drop_numeric]\n",
    "\n",
    "# --- Step 2: Drop low-importance categorical features (Cramér's V with target) ---\n",
    "def cramers_v(x, y):\n",
    "    \"\"\"Robust Cramér's V with bias correction.\n",
    "    Returns 0.0 for degenerate tables and guards against divide-by-zero.\n",
    "    \"\"\"\n",
    "    cm = pd.crosstab(x, y)\n",
    "    n = cm.values.sum()\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "    r, k = cm.shape\n",
    "    if r == 1 or k == 1:\n",
    "        return 0.0\n",
    "    chi2 = chi2_contingency(cm, correction=False)[0]\n",
    "    phi2 = chi2 / n\n",
    "    phi2corr = max(0.0, phi2 - ((k - 1) * (r - 1)) / (n - 1)) if n > 1 else 0.0\n",
    "    rcorr = r - ((r - 1) ** 2) / (n - 1) if n > 1 else r\n",
    "    kcorr = k - ((k - 1) ** 2) / (n - 1) if n > 1 else k\n",
    "    denom = min((kcorr - 1), (rcorr - 1))\n",
    "    if denom <= 0:\n",
    "        return 0.0\n",
    "    return float(np.sqrt(phi2corr / denom))\n",
    "\n",
    "cat_corr = {c: cramers_v(df_proc[c], df_proc[target_col]) for c in cat_cols}\n",
    "cat_corr = pd.Series(cat_corr).sort_values(ascending=False)\n",
    "drop_categorical = list(cat_corr[cat_corr < 0.05].index)\n",
    "final_categorical = [c for c in cat_cols if c not in drop_categorical]\n",
    "\n",
    "# --- Step 3: Remove outliers from numeric columns using IQR ---\n",
    "df_clean = df_proc.copy()\n",
    "for col in final_numeric:\n",
    "    Q1 = df_clean[col].quantile(0.25)\n",
    "    Q3 = df_clean[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    before_count = df_clean.shape[0]\n",
    "    df_clean = df_clean[(df_clean[col] >= lower) & (df_clean[col] <= upper)]\n",
    "    after_count = df_clean.shape[0]\n",
    "    if before_count != after_count:\n",
    "        print(f\"Removed {before_count - after_count} outliers from '{col}'\")\n",
    "\n",
    "# --- Step 4: Generate final cleaned feature set ---\n",
    "X_final = df_clean[final_numeric + final_categorical]\n",
    "y_final = df_clean[target_col]\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n--- Final Cleaned Feature List ---\")\n",
    "print(\"Dropped numeric features (highly correlated):\", drop_numeric)\n",
    "print(\"Dropped categorical features (low association with target):\", drop_categorical)\n",
    "print(f\"Remaining numeric features ({len(final_numeric)}):\", final_numeric)\n",
    "print(f\"Remaining categorical features ({len(final_categorical)}):\", final_categorical)\n",
    "print(f\"Final cleaned dataset shape: {X_final.shape}\")\n",
    "\n",
    "display(X_final.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0364918d",
   "metadata": {},
   "source": [
    "## Model training plan\n",
    "Train 6 ML models (with tuned hyperparameters):\n",
    "- Logistic Regression (Multinomial)\n",
    "- Random Forest\n",
    "- Gradient Boosting (XGBoost)\n",
    "- Support Vector Machine (SVM, RBF kernel)\n",
    "- k-Nearest Neighbors (KNN)\n",
    "- Decision Tree\n",
    "\n",
    "We will train on the preprocessed, encoded, scaled training data and evaluate on test set with Accuracy, Precision, Recall and F1-score metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef26564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Preparation ---\n",
    "# Use X_final and y_final (clean, feature-selected data from correlation analysis)\n",
    "X_data = X_final.copy()\n",
    "y_data = y_final.copy()\n",
    "\n",
    "# Identify categorical and numeric columns in X_final\n",
    "final_cat_cols = [c for c in X_final.columns if c not in final_numeric]\n",
    "\n",
    "# Train-test split (stratified)\n",
    "X_train_ml, X_test_ml, y_train_ml, y_test_ml = train_test_split(\n",
    "    X_data, y_data, test_size=0.2, random_state=42, stratify=y_data\n",
    ")\n",
    "\n",
    "# One-hot encode categorical features\n",
    "if final_cat_cols:\n",
    "    ohe_final = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    X_train_cat_enc = ohe_final.fit_transform(X_train_ml[final_cat_cols])\n",
    "    X_test_cat_enc = ohe_final.transform(X_test_ml[final_cat_cols])\n",
    "    \n",
    "    # Get encoded column names\n",
    "    cat_encoded_cols = ohe_final.get_feature_names_out(final_cat_cols)\n",
    "    \n",
    "    # Convert to DataFrames with numeric columns\n",
    "    X_train_ml_numeric = X_train_ml[final_numeric].reset_index(drop=True)\n",
    "    X_test_ml_numeric = X_test_ml[final_numeric].reset_index(drop=True)\n",
    "    \n",
    "    X_train_cat_df = pd.DataFrame(X_train_cat_enc, columns=cat_encoded_cols)\n",
    "    X_test_cat_df = pd.DataFrame(X_test_cat_enc, columns=cat_encoded_cols)\n",
    "    \n",
    "    # Combine numeric and encoded categorical\n",
    "    X_train_ml = pd.concat([X_train_ml_numeric, X_train_cat_df], axis=1)\n",
    "    X_test_ml = pd.concat([X_test_ml_numeric, X_test_cat_df], axis=1)\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train_ml[final_numeric] = scaler.fit_transform(X_train_ml[final_numeric])\n",
    "X_test_ml[final_numeric] = scaler.transform(X_test_ml[final_numeric])\n",
    "\n",
    "# Encode target variable if categorical\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train_ml)\n",
    "y_test_enc = le.transform(y_test_ml)\n",
    "n_classes = len(le.classes_)\n",
    "\n",
    "print(f\"Training set shape: {X_train_ml.shape}\")\n",
    "print(f\"Test set shape: {X_test_ml.shape}\")\n",
    "print(f\"Number of classes: {n_classes}\")\n",
    "print(f\"Classes: {le.classes_}\")\n",
    "\n",
    "# --- Define 6 ML Models ---\n",
    "models = {\n",
    "    \"Logistic Regression (Multinomial)\": LogisticRegression(\n",
    "        multi_class='multinomial', max_iter=1000, random_state=42, solver='lbfgs'\n",
    "    ),\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=200, max_depth=20, random_state=42, n_jobs=-1\n",
    "    ),\n",
    "    \"Gradient Boosting (XGBoost)\": xgb.XGBClassifier(\n",
    "        n_estimators=200, learning_rate=0.1, max_depth=6, random_state=42, \n",
    "        eval_metric='mlogloss', use_label_encoder=False, verbosity=0\n",
    "    ) if has_xgb else None,\n",
    "    \"Support Vector Machine (SVM)\": SVC(\n",
    "        kernel='rbf', C=1.0, probability=True, random_state=42\n",
    "    ),\n",
    "    \"k-Nearest Neighbors (KNN)\": KNeighborsClassifier(\n",
    "        n_neighbors=7, weights='distance', n_jobs=-1\n",
    "    ),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(\n",
    "        max_depth=20, min_samples_split=5, random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# Remove None models if XGBoost not available\n",
    "models = {k: v for k, v in models.items() if v is not None}\n",
    "\n",
    "# --- Train models and collect results ---\n",
    "results_list = []\n",
    "trained_models = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining: {model_name}...\")\n",
    "    \n",
    "    try:\n",
    "        # Train\n",
    "        model.fit(X_train_ml, y_train_enc)\n",
    "        trained_models[model_name] = model\n",
    "        \n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test_ml)\n",
    "        \n",
    "        # Compute metrics\n",
    "        accuracy = accuracy_score(y_test_enc, y_pred)\n",
    "        precision = precision_score(y_test_enc, y_pred, average='weighted', zero_division=0)\n",
    "        recall = recall_score(y_test_enc, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test_enc, y_pred, average='weighted', zero_division=0)\n",
    "        \n",
    "        # ROC-AUC (only if binary, else use ovr or ovo)\n",
    "        try:\n",
    "            if n_classes == 2:\n",
    "                roc_auc = roc_auc_score(y_test_enc, model.predict_proba(X_test_ml)[:, 1])\n",
    "            else:\n",
    "                roc_auc = roc_auc_score(y_test_enc, model.predict_proba(X_test_ml), multi_class='ovr', zero_division=0)\n",
    "        except:\n",
    "            roc_auc = np.nan\n",
    "        \n",
    "        results_list.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Accuracy\": round(accuracy, 4),\n",
    "            \"Precision\": round(precision, 4),\n",
    "            \"Recall\": round(recall, 4),\n",
    "            \"F1-Score\": round(f1, 4)\n",
    "        })\n",
    "        \n",
    "        print(f\"✓ {model_name} - Accuracy: {accuracy:.4f}, F1: {f1:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error training {model_name}: {str(e)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Model training complete!\")\n",
    "# --- Create Comparison Table ---\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Sort by F1-Score (descending)\n",
    "results_df = results_df.sort_values(by=\"F1-Score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON TABLE\")\n",
    "print(\"=\"*80)\n",
    "display(results_df)\n",
    "\n",
    "# --- CONFUSION MATRICES FOR EACH MODEL ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONFUSION MATRICES - Individual Models\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "n_models = len(trained_models)\n",
    "fig, axes = plt.subplots((n_models + 1) // 2, 2, figsize=(16, 5 * ((n_models + 1) // 2)))\n",
    "if n_models == 1:\n",
    "    axes = [axes]\n",
    "else:\n",
    "    axes = axes.flatten()\n",
    "\n",
    "confusion_matrices = {}\n",
    "\n",
    "for idx, (model_name, model) in enumerate(trained_models.items()):\n",
    "    y_pred = model.predict(X_test_ml)\n",
    "    cm = confusion_matrix(y_test_enc, y_pred)\n",
    "    confusion_matrices[model_name] = cm\n",
    "    \n",
    "    ax = axes[idx]\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, \n",
    "                xticklabels=le.classes_, yticklabels=le.classes_,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    ax.set_title(f\"Confusion Matrix: {model_name}\\n(F1-Score: {results_df[results_df['Model'] == model_name]['F1-Score'].values[0]:.4f})\")\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "\n",
    "# Remove extra subplots if odd number of models\n",
    "if n_models % 2 == 1:\n",
    "    fig.delaxes(axes[-1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- DETAILED CLASSIFICATION REPORTS ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED CLASSIFICATION REPORTS - Per Model\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for model_name, model in trained_models.items():\n",
    "    y_pred = model.predict(X_test_ml)\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(classification_report(y_test_enc, y_pred, target_names=le.classes_, digits=4))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv(OUTPUT_FOLDER / 'model_comparison_table.csv', index=False)\n",
    "print(\"\\n✓ Saved model comparison table to: model_comparison_table.csv\")\n",
    "\n",
    "# Additional summary statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Best Model (by F1-Score): {results_df.iloc[0]['Model']}\")\n",
    "print(f\"Best F1-Score: {results_df.iloc[0]['F1-Score']}\")\n",
    "print(f\"\\nAverage Metrics Across All Models:\")\n",
    "print(f\"  Accuracy:  {results_df['Accuracy'].mean():.4f}\")\n",
    "print(f\"  Precision: {results_df['Precision'].mean():.4f}\")\n",
    "print(f\"  Recall:    {results_df['Recall'].mean():.4f}\")\n",
    "print(f\"  F1-Score:  {results_df['F1-Score'].mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ed74e3",
   "metadata": {},
   "source": [
    "## Saving outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33738706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the OUTPUT_FOLDER defined in the setup cell\n",
    "print(f\"Saving datasets to: {OUTPUT_FOLDER}\")\n",
    "\n",
    "# --- Save processed training/test datasets ---\n",
    "# Use X_train_ml, X_test_ml from model training (already encoded and scaled)\n",
    "X_train_ml.to_csv(OUTPUT_FOLDER / 'X_train_processed.csv', index=False)\n",
    "X_test_ml.to_csv(OUTPUT_FOLDER / 'X_test_processed.csv', index=False)\n",
    "\n",
    "# Save target variables\n",
    "pd.Series(y_train_ml, name='EPDS Result').to_csv(OUTPUT_FOLDER / 'y_train_processed.csv', index=False)\n",
    "pd.Series(y_test_ml, name='EPDS Result').to_csv(OUTPUT_FOLDER / 'y_test_processed.csv', index=False)\n",
    "\n",
    "print(\"✓ Saved processed training/test sets:\")\n",
    "print(f\"  - X_train_processed.csv ({X_train_ml.shape})\")\n",
    "print(f\"  - X_test_processed.csv ({X_test_ml.shape})\")\n",
    "print(f\"  - y_train_processed.csv ({len(y_train_ml)} samples)\")\n",
    "print(f\"  - y_test_processed.csv ({len(y_test_ml)} samples)\")\n",
    "\n",
    "# --- Save feature information ---\n",
    "feature_info = pd.DataFrame({\n",
    "    'Feature': X_train_ml.columns,\n",
    "    'Type': ['Numeric' if col in final_numeric else 'Categorical (One-Hot Encoded)' for col in X_train_ml.columns]\n",
    "})\n",
    "feature_info.to_csv(OUTPUT_FOLDER / 'feature_info.csv', index=False)\n",
    "print(f\"\\n✓ Saved feature information: feature_info.csv ({len(feature_info)} features)\")\n",
    "\n",
    "# --- Save model comparison results ---\n",
    "# results_df is already saved to model_comparison_table.csv from earlier\n",
    "print(f\"\\n✓ Model comparison table already saved: model_comparison_table.csv\")\n",
    "print(f\"  Best Model: {results_df.iloc[0]['Model']}\")\n",
    "print(f\"  Best F1-Score: {results_df.iloc[0]['F1-Score']}\")\n",
    "\n",
    "# --- Save metadata ---\n",
    "metadata = {\n",
    "    'Dataset': 'PPD_dataset_v2.csv',\n",
    "    'Original Shape': str(df.shape),\n",
    "    'After Preprocessing': str(df_proc.shape),\n",
    "    'After Feature Selection': str(X_final.shape),\n",
    "    'Final Train Set Shape': str(X_train_ml.shape),\n",
    "    'Final Test Set Shape': str(X_test_ml.shape),\n",
    "    'Target Variable': 'EPDS Result',\n",
    "    'Target Classes': str(list(le.classes_)),\n",
    "    'Train/Test Split': '80/20 (Stratified)',\n",
    "    'Numeric Features': str(final_numeric),\n",
    "    'Categorical Features Dropped': str(drop_categorical),\n",
    "    'Numeric Features Dropped': str(drop_numeric)\n",
    "}\n",
    "\n",
    "metadata_df = pd.DataFrame(list(metadata.items()), columns=['Key', 'Value'])\n",
    "metadata_df.to_csv(OUTPUT_FOLDER / 'preprocessing_metadata.csv', index=False)\n",
    "print(f\"\\n✓ Saved preprocessing metadata: preprocessing_metadata.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL OUTPUTS SAVED SUCCESSFULLY!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652e8375",
   "metadata": {},
   "source": [
    "# Pipeline Summary & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e608cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DYNAMIC PIPELINE SUMMARY ---\n",
    "\n",
    "# Gather all dynamic data from previous cells\n",
    "summary_md = \"\"\n",
    "\n",
    "# --- Data Processing Pipeline ---\n",
    "summary_md += \"#### Data Processing Pipeline\\n\"\n",
    "summary_md += f\"- **Original Dataset**: {df.shape[0]} samples × {df.shape[1]} features\\n\"\n",
    "summary_md += f\"- **After Preprocessing**: {df_proc.shape[0]} samples × {df_proc.shape[1]} features (missing values imputed)\\n\"\n",
    "summary_md += f\"- **After Feature Selection**: {X_final.shape[0]} samples × {X_final.shape[1]} features (highly correlated features dropped)\\n\"\n",
    "summary_md += f\"- **Final Train Set**: {X_train_ml.shape[0]} samples × {X_train_ml.shape[1]} features (encoded & scaled)\\n\"\n",
    "summary_md += f\"- **Final Test Set**: {X_test_ml.shape[0]} samples × {X_test_ml.shape[1]} features (encoded & scaled)\\n\\n\"\n",
    "\n",
    "# --- Model Rankings ---\n",
    "summary_md += \"#### ML Models Trained & Ranked by F1-Score\\n\\n\"\n",
    "summary_md += \"| Rank | Model | Accuracy | Precision | Recall | F1-Score |\\n\"\n",
    "summary_md += \"|------|-------|----------|-----------|--------|----------|\\n\"\n",
    "for idx, row in results_df.iterrows():\n",
    "    summary_md += f\"| {idx+1} | {row['Model']} | {row['Accuracy']:.4f} | {row['Precision']:.4f} | {row['Recall']:.4f} | {row['F1-Score']:.4f} |\\n\"\n",
    "\n",
    "# --- Overall Statistics ---\n",
    "summary_md += \"\\n**Overall Statistics**:\\n\"\n",
    "summary_md += f\"- Average Accuracy: {results_df['Accuracy'].mean() * 100:.2f}%\\n\"\n",
    "summary_md += f\"- Average Precision: {results_df['Precision'].mean():.4f}\\n\"\n",
    "summary_md += f\"- Average Recall: {results_df['Recall'].mean():.4f}\\n\"\n",
    "summary_md += f\"- Average F1-Score: {results_df['F1-Score'].mean():.4f}\\n\"\n",
    "summary_md += f\"- Best Model: **{results_df.iloc[0]['Model']}** (F1: {results_df.iloc[0]['F1-Score']:.4f})\\n\\n\"\n",
    "\n",
    "# --- Output Files Saved ---\n",
    "summary_md += f\"#### Output Files Saved to: `{OUTPUT_FOLDER}`\\n\\n\"\n",
    "summary_md += \"| File | Shape/Details | Purpose |\\n\"\n",
    "summary_md += \"|------|---|----------|\\n\"\n",
    "summary_md += f\"| `X_train_processed.csv` | {X_train_ml.shape} | Processed training features (encoded & scaled) |\\n\"\n",
    "summary_md += f\"| `X_test_processed.csv` | {X_test_ml.shape} | Processed test features (encoded & scaled) |\\n\"\n",
    "summary_md += f\"| `y_train_processed.csv` | {len(y_train_ml)} samples | Training target labels (EPDS Result) |\\n\"\n",
    "summary_md += f\"| `y_test_processed.csv` | {len(y_test_ml)} samples | Test target labels (EPDS Result) |\\n\"\n",
    "summary_md += f\"| `model_comparison_table.csv` | {len(results_df)} models | Model performance metrics |\\n\"\n",
    "summary_md += f\"| `feature_info.csv` | {X_train_ml.shape[1]} features | Feature names and types |\\n\"\n",
    "summary_md += f\"| `preprocessing_metadata.csv` | Key-value pairs | Pipeline configuration & details |\\n\\n\"\n",
    "\n",
    "# --- Target Variable ---\n",
    "summary_md += \"#### Target Variable\\n\"\n",
    "summary_md += f\"- **Name**: EPDS Result (Edinburgh Postpartum Depression Scale)\\n\"\n",
    "summary_md += f\"- **Classes**: {', '.join(le.classes_)}\\n\"\n",
    "summary_md += f\"- **Class Distribution**: {dict(Counter(y_final))}\\n\"\n",
    "summary_md += f\"- **Class Balance**: Stratified train/test split (80/20)\\n\"\n",
    "summary_md += f\"- **Prediction Task**: Multi-class classification of postpartum depression risk\\n\\n\"\n",
    "\n",
    "# --- Features Summary ---\n",
    "summary_md += \"#### Feature Summary\\n\"\n",
    "summary_md += f\"- **Numeric Features Used**: {', '.join(final_numeric)}\\n\"\n",
    "summary_md += f\"- **Numeric Features Dropped**: {drop_numeric if drop_numeric else 'None'}\\n\"\n",
    "summary_md += f\"- **Categorical Features Used**: {len(final_categorical)} features\\n\"\n",
    "summary_md += f\"- **Categorical Features Dropped**: {len(drop_categorical)} features (low correlation with target)\\n\\n\"\n",
    "\n",
    "# Display as markdown\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(summary_md))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
